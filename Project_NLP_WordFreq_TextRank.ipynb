{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the CNN Daily Mail Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN-DailyMail Dataset:\n",
    "\n",
    "https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail\n",
    "\n",
    "Amazon Reviews Dataset:\n",
    "\n",
    "https://www.kaggle.com/code/currie32/summarizing-text-with-amazon-reviews/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('cnn_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
       "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
       "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "      <td>A drunk driver who killed a young woman in a h...</td>\n",
       "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
       "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
       "      <td>Fleetwood are the only team still to have a 10...</td>\n",
       "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287108</th>\n",
       "      <td>fffdfb56fdf1a12d364562cc2b9b1d4de7481dee</td>\n",
       "      <td>By . James Rush . Former first daughter Chelse...</td>\n",
       "      <td>Chelsea Clinton said question of running for o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287109</th>\n",
       "      <td>fffeecb8690b85de8c3faed80adbc7a978f9ae2a</td>\n",
       "      <td>An apologetic Vanilla Ice has given his first ...</td>\n",
       "      <td>Vanilla Ice, 47 - real name Robert Van Winkle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287110</th>\n",
       "      <td>ffff5231e4c71544bc6c97015cdb16c60e42b3f4</td>\n",
       "      <td>America's most lethal sniper claimed he wished...</td>\n",
       "      <td>America's most lethal sniper made comment in i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287111</th>\n",
       "      <td>ffff924b14a8d82058b6c1c5368ff1113c1632af</td>\n",
       "      <td>By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...</td>\n",
       "      <td>A swarm of more than one million has crossed b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287112</th>\n",
       "      <td>ffffd563a96104f5cf4493cfa701a65f31b06abf</td>\n",
       "      <td>(CNN)Former Florida Gov. Jeb Bush has decided ...</td>\n",
       "      <td>Other 2016 hopefuls maintain that Bush's annou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287113 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  \\\n",
       "0       0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
       "1       0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
       "2       00027e965c8264c35cc1bc55556db388da82b07f   \n",
       "3       0002c17436637c4fe1837c935c04de47adb18e9a   \n",
       "4       0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
       "...                                          ...   \n",
       "287108  fffdfb56fdf1a12d364562cc2b9b1d4de7481dee   \n",
       "287109  fffeecb8690b85de8c3faed80adbc7a978f9ae2a   \n",
       "287110  ffff5231e4c71544bc6c97015cdb16c60e42b3f4   \n",
       "287111  ffff924b14a8d82058b6c1c5368ff1113c1632af   \n",
       "287112  ffffd563a96104f5cf4493cfa701a65f31b06abf   \n",
       "\n",
       "                                                  article  \\\n",
       "0       By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
       "1       (CNN) -- Ralph Mata was an internal affairs li...   \n",
       "2       A drunk driver who killed a young woman in a h...   \n",
       "3       (CNN) -- With a breezy sweep of his pen Presid...   \n",
       "4       Fleetwood are the only team still to have a 10...   \n",
       "...                                                   ...   \n",
       "287108  By . James Rush . Former first daughter Chelse...   \n",
       "287109  An apologetic Vanilla Ice has given his first ...   \n",
       "287110  America's most lethal sniper claimed he wished...   \n",
       "287111  By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...   \n",
       "287112  (CNN)Former Florida Gov. Jeb Bush has decided ...   \n",
       "\n",
       "                                               highlights  \n",
       "0       Bishop John Folda, of North Dakota, is taking ...  \n",
       "1       Criminal complaint: Cop used his role to help ...  \n",
       "2       Craig Eccleston-Todd, 27, had drunk at least t...  \n",
       "3       Nina dos Santos says Europe must be ready to a...  \n",
       "4       Fleetwood top of League One after 2-0 win at S...  \n",
       "...                                                   ...  \n",
       "287108  Chelsea Clinton said question of running for o...  \n",
       "287109  Vanilla Ice, 47 - real name Robert Van Winkle ...  \n",
       "287110  America's most lethal sniper made comment in i...  \n",
       "287111  A swarm of more than one million has crossed b...  \n",
       "287112  Other 2016 hopefuls maintain that Bush's annou...  \n",
       "\n",
       "[287113 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Text Summarization using TF-IDF Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nanda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nanda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_table(text_string) -> dict:\n",
    "    \"\"\"\n",
    "    we create a dictionary for the word frequency table.\n",
    "    For this, we should only use the words that are not part of the stopWords array.\n",
    "\n",
    "    Removing stop words and making frequency table\n",
    "    Stemmer - an algorithm to bring words to its root word.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text_string)\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else:\n",
    "            freqTable[word] = 1\n",
    "\n",
    "    return freqTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_summarization(text):\n",
    "    \"\"\"\n",
    "    :param text: Plain summary_text of long article\n",
    "    :return: summarized summary_text\n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    We already have a sentence tokenizer, so we just need \n",
    "    to run the sent_tokenize() method to create the array of sentences.\n",
    "    '''\n",
    "    # 1 Sentence Tokenize\n",
    "    sentences = sent_tokenize(text)\n",
    "    total_documents = len(sentences)\n",
    "    #print(sentences)\n",
    "\n",
    "    # 2 Create the Frequency matrix of the words in each sentence.\n",
    "    freq_matrix = _create_frequency_matrix(sentences)\n",
    "    #print(freq_matrix)\n",
    "\n",
    "    '''\n",
    "    Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
    "    '''\n",
    "    # 3 Calculate TermFrequency and generate a matrix\n",
    "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    #print(tf_matrix)\n",
    "\n",
    "    # 4 creating table for documents per words\n",
    "    count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "    #print(count_doc_per_words)\n",
    "\n",
    "    '''\n",
    "    Inverse document frequency (IDF) is how unique or rare a word is.\n",
    "    '''\n",
    "    # 5 Calculate IDF and generate a matrix\n",
    "    idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "    #print(idf_matrix)\n",
    "\n",
    "    # 6 Calculate TF-IDF and generate a matrix\n",
    "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    #print(tf_idf_matrix)\n",
    "\n",
    "    # 7 Important Algorithm: score the sentences\n",
    "    sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "    #print(sentence_scores)\n",
    "\n",
    "    # 8 Find the threshold\n",
    "    threshold = _find_average_score(sentence_scores)\n",
    "    #print(threshold)\n",
    "\n",
    "    # 9 Important Algorithm: Generate the summary\n",
    "    summary = _generate_summary(sentences, sentence_scores,0.6*threshold)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_summarization(train_df['article'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['highlights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summaries=train_df['highlights'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_summaries=[]\n",
    "for i in range(100):\n",
    "    predicted_summaries.append(run_summarization(train_df['article'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Text Summarization using TextRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextRank(sentences):\n",
    "    #preprocessing the sentences\n",
    "    sentences_clean=[re.sub(r'[^\\w\\s]','',sentence.lower()) for sentence in sentences]\n",
    "    #removing the stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    #tokenizing the words in each sentence after cleaning.\n",
    "    sentence_tokens=[[words for words in sentence.split(' ') if words not in stop_words] for sentence in sentences_clean]\n",
    "    #calculating word embeddings for each word of the text.\n",
    "    w2v=Word2Vec(sentence_tokens,vector_size=1,min_count=1,epochs=1000)\n",
    "    #replacing word tokens with their embedding in sentence tokens.\n",
    "    sentence_embeddings=[[w2v.wv[word][0] for word in words] for words in sentence_tokens]\n",
    "    #max length of a sentence in the existing text\n",
    "    max_len=max([len(tokens) for tokens in sentence_tokens])\n",
    "    #padding sentence embedding using 0's to max_len.\n",
    "    sentence_embeddings=[np.pad(embedding,(0,max_len-len(embedding)),'constant') for embedding in sentence_embeddings]\n",
    "    #initializing similarity matrix.\n",
    "    similarity_matrix = np.zeros([len(sentence_tokens), len(sentence_tokens)])\n",
    "    #calculating the similarity between every two pairs of sentences.\n",
    "    for i,row_embedding in enumerate(sentence_embeddings):\n",
    "        for j,column_embedding in enumerate(sentence_embeddings):\n",
    "            similarity_matrix[i][j]=1-spatial.distance.cosine(row_embedding,column_embedding)\n",
    "    #converting the similarity matrix to network\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    #applying page rank\n",
    "    scores = nx.pagerank(nx_graph,max_iter=1000)\n",
    "    #retrieving the top 4 sentences.\n",
    "    top_sentence={sentence:scores[index] for index,sentence in enumerate(sentences)}\n",
    "    top=dict(sorted(top_sentence.items(), key=lambda x: x[1], reverse=True)[:4])\n",
    "    result=''\n",
    "    for sent in sentences:\n",
    "        if sent in top.keys():\n",
    "            result+=sent\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the sentences and performing the Text Rank algorithm.\n",
    "predicted_summaries_textrank=[]\n",
    "for i in range(100):\n",
    "    sentences=sent_tokenize(train_df['article'][i])\n",
    "    predicted_summaries_textrank.append(TextRank(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map â€“ a problem that has haunted cartographers for centuries.Photo of a genuine hand drawn world map, it was drawn in 1844 and therefore the countries are named as they were in that period.Almost for the first time, the ability to create an accurate map has been placed in the hands of everyone, and it has transformed the way we view the world.Richard Oswald, secretary to the delegation, annotated it with coloured lines to show where it was thought past treaties established the U.S./Canada border .'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_summaries_textrank[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distortion is the result of the Mercator map which was created in 1596 to help sailors navigate the world .\\nIt gives the right shapes of countries but at the cost of distorting sizes in favour of the wealthy lands to the north .\\nFor instance, north America looks larger, or at least as big, as Africa, and Greenland also looks of comparable size .\\nIn reality, you can fit north America into Africa and still have space for India, Argentina, Tunisia and some left over .\\nMap suggests Scandinavian countries are larger than India, whereas in reality India is three times the size .\\nThe biggest challenge for cartographers is that it is impossible to portray reality of spherical world on a flat map .'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summaries[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rouge_scores(pred_summaries, gold_summaries, \n",
    "\n",
    "                                 keys=['rouge1', 'rougeL'], use_stemmer=True):\n",
    "\n",
    "    #Calculate rouge scores\n",
    "    scorer = rouge_scorer.RougeScorer(keys, use_stemmer= use_stemmer)\n",
    "    n = len(pred_summaries)\n",
    "    scores = [scorer.score(pred_summaries[j], gold_summaries[j]) for \n",
    "              j in range(n)] \n",
    "    dict_scores={}                                                            \n",
    "    for key in keys:\n",
    "        dict_scores.update({key: {}})\n",
    "    for key in keys:\n",
    "        precision_list = [scores[j][key][0] for j in range(len(scores))]\n",
    "        recall_list = [scores[j][key][1] for j in range(len(scores))]\n",
    "        f1_list = [scores[j][key][2] for j in range(len(scores))]\n",
    "        precision = np.mean(precision_list)\n",
    "        recall = np.mean(recall_list)\n",
    "        f1 = np.mean(f1_list)\n",
    "        dict_results = {'recall': recall, 'precision': precision, 'f1': f1}\n",
    "        dict_scores[key] = dict_results\n",
    "    return dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge score for TF-IDF Algorithm for CNN Daily Mail Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores_word_frequency=calc_rouge_scores(predicted_summaries,test_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'recall': 0.09882362037622135,\n",
       "  'precision': 0.7592652905987959,\n",
       "  'f1': 0.16921104279217225},\n",
       " 'rougeL': {'recall': 0.06490876495936519,\n",
       "  'precision': 0.5082022047646378,\n",
       "  'f1': 0.11150274482492267}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_scores_word_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge score for Text Rank Algorithm for CNN Daily Mail Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores_text_rank=calc_rouge_scores(predicted_summaries_textrank,test_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'recall': 0.2258022443394076,\n",
       "  'precision': 0.3250931570029875,\n",
       "  'f1': 0.26019769051179276},\n",
       " 'rougeL': {'recall': 0.12215636087996319,\n",
       "  'precision': 0.1804242219771743,\n",
       "  'f1': 0.1426723748129462}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_scores_text_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Amazon Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amazon_reviews=pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge score for TF-IDF Algorithm for Amazon Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_summaries_amazon=[]\n",
    "for i in range(100):\n",
    "    predicted_summaries_amazon.append(run_summarization(train_amazon_reviews['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores_amazon_word_frequency=calc_rouge_scores(predicted_summaries_amazon,train_amazon_reviews['Text'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'recall': 1.0,\n",
       "  'precision': 0.7740426749493853,\n",
       "  'f1': 0.830507044288203},\n",
       " 'rougeL': {'recall': 1.0,\n",
       "  'precision': 0.7740426749493853,\n",
       "  'f1': 0.830507044288203}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_scores_amazon_word_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge score for Text Rank Algorithm for Amazon Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_summaries_amazon_textrank=[]\n",
    "for i in range(100):\n",
    "    sentences=sent_tokenize(train_amazon_reviews['Text'][i])\n",
    "    predicted_summaries_amazon_textrank.append(TextRank(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'recall': 1.0,\n",
       "  'precision': 0.8655913978494624,\n",
       "  'f1': 0.9080882352941176},\n",
       " 'rougeL': {'recall': 1.0,\n",
       "  'precision': 0.8655913978494624,\n",
       "  'f1': 0.9080882352941176}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_scores_amazon_text_rank=calc_rouge_scores(predicted_summaries_amazon_textrank,train_amazon_reviews['Text'][:100])\n",
    "dict_scores_amazon_text_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_amazon_lstm_df=pd.read_csv('predicted.csv')\n",
    "original_amazon_lstm_df=pd.read_csv('original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' not for me'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_amazon_lstm_df['predicted_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hour '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_amazon_lstm_df['original_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_summary_amazon_lstm=[]\n",
    "original_summary_amazon_lstm=[]\n",
    "for i in range(predicted_amazon_lstm_df.shape[0]):\n",
    "    predicted_summary_amazon_lstm.append(predicted_amazon_lstm_df['predicted_summary'][i])\n",
    "    original_summary_amazon_lstm.append(original_amazon_lstm_df['original_summary'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores_amazon_lstm=calc_rouge_scores(predicted_summary_amazon_lstm,original_summary_amazon_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'recall': 0.26208333333333333,\n",
       "  'precision': 0.17885714285714285,\n",
       "  'f1': 0.20119047619047617},\n",
       " 'rougeL': {'recall': 0.26208333333333333,\n",
       "  'precision': 0.17885714285714285,\n",
       "  'f1': 0.20119047619047617}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_scores_amazon_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
